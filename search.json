[
  {
    "objectID": "posts/gatsby.html",
    "href": "posts/gatsby.html",
    "title": "Gatsby",
    "section": "",
    "text": "This should include a description of your data, a link to the source(s) of your data, your motivation for looking at the data, and the question(s) that you are seeking to address. For my final project, I will be analyzing the novel The Great Gatsby by F. Scott Fitzgerald. The source for my project is The Gutenberg Project, which has provided the text of the novel.\nFitzgerald’s The Great Gatsby is my favorite novel, and I first read it in a high school English class. I was enamored by the themes of love and the American dream as well as the lively setting and time period. During my first read of the book, I analyzed the texts from a literary standpoint. Now, I hope to perform the same analysis from a digital humanities perspective using data science. I would like to explore the themes of the novel by analyzing word frequencies and sentiment. I also plan to look into the role certain characters play in portraying themes of the Roaring Twenties.\n\nimport requests\nimport matplotlib.pyplot as plt\nimport nltk\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.sentiment import vader\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import opinion_lexicon\nfrom nltk.stem.porter import PorterStemmer\n\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('vader_lexicon')\nnltk.download('opinion_lexicon')\n\n[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n[nltk_data] Downloading package opinion_lexicon to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package opinion_lexicon is already up-to-date!\n\n\nTrue\n\n\n\ntarget_url = \"https://www.gutenberg.org/cache/epub/64317/pg64317.txt\"\nresponse = requests.get(target_url)\ngatsby_string = response.text\ngatsby_string = gatsby_string.split('*** START OF THE PROJECT GUTENBERG EBOOK THE GREAT GATSBY ***')[1]\ngatsby_string = gatsby_string.split('*** END OF THE PROJECT GUTENBERG EBOOK THE GREAT GATSBY ***')[0]\ngatsby_string = gatsby_string.lower()\n\n\nstopwords_list = stopwords.words('english')\n# print(stopwords_list)\nsia = vader.SentimentIntensityAnalyzer()\n\n\ngatsby_word_list = [w for w in word_tokenize(gatsby_string.lower())]\n\n\nreviewPolarity = 0.0\npos_list = []\nneg_list = []\nfor word in gatsby_word_list:\n  val = sia.polarity_scores(word)['compound']\n  if val > 0:\n    pos_list.append(word)\n  elif val < 0:\n    neg_list.append(word)\nprint(pos_list[0:10])\nprint(neg_list[0:10])\n\n['great', 'lover', 'lover', 'like', 'advantages', 'great', 'curious', 'matter', 'hope', 'tolerance']\n['cry', 'vulnerable', 'criticizing', 'victim', 'bores', 'accused', 'hostile', 'missing', 'forget', 'snobbishly']\n\n\n\ntop15_pos = nltk.FreqDist(pos_list).most_common(15)\ntop15_neg = nltk.FreqDist(neg_list).most_common(15)\n\nprint(top15_pos)\nprint(top15_neg)\n\n[('like', 119), ('hand', 63), ('want', 59), ('well', 53), ('good', 30), ('great', 26), ('love', 24), ('god', 20), ('matter', 19), ('loved', 19), ('friend', 18), ('party', 18), ('won', 17), ('better', 17), ('bright', 16)]\n[('no', 97), ('miss', 38), ('cried', 31), ('alone', 25), ('demanded', 24), ('broke', 23), ('stopped', 19), ('hard', 17), ('shook', 17), ('crazy', 14), ('stop', 13), ('bad', 11), ('leave', 11), ('lost', 11), ('killed', 11)]\n\n\n\nno_stopwords = [w for w in word_tokenize(gatsby_string.lower()) if w not in stopwords_list]\n\nreviewPolarity = 0.0\npos_list = []\nneg_list = []\nfor word in no_stopwords:\n  val = sia.polarity_scores(word)['compound']\n  if val > 0:\n    pos_list.append(word)\n  elif val < 0:\n    neg_list.append(word)\ntop15_pos = nltk.FreqDist(pos_list).most_common(15)\ntop15_neg = nltk.FreqDist(neg_list).most_common(15)\n\nprint(top15_pos)\nprint(top15_neg)\n\n[('like', 119), ('hand', 63), ('want', 59), ('well', 53), ('good', 30), ('great', 26), ('love', 24), ('god', 20), ('matter', 19), ('loved', 19), ('friend', 18), ('party', 18), ('better', 17), ('bright', 16), ('yes', 16)]\n[('miss', 38), ('cried', 31), ('alone', 25), ('demanded', 24), ('broke', 23), ('stopped', 19), ('hard', 17), ('shook', 17), ('crazy', 14), ('stop', 13), ('bad', 11), ('leave', 11), ('lost', 11), ('killed', 11), ('dead', 11)]\n\n\n\nstemmer = PorterStemmer()\nunstemmed = [w for w in word_tokenize(gatsby_string.lower()) if w not in stopwords_list]\nstemmed = []\nfor word in unstemmed:\n  stemmed.append(stemmer.stem(word))\n\nreviewPolarity = 0.0\npos_list = []\nneg_list = []\nfor word in stemmed:\n  val = sia.polarity_scores(word)['compound']\n  if val > 0:\n    pos_list.append(word)\n  elif val < 0:\n    neg_list.append(word)\ntop15_pos = nltk.FreqDist(pos_list).most_common(15)\ntop15_neg = nltk.FreqDist(neg_list).most_common(15)\n\nprint(top15_pos)\nprint(top15_neg)\n\n[('like', 128), ('hand', 103), ('want', 97), ('love', 56), ('well', 53), ('good', 30), ('great', 26), ('laugh', 25), ('matter', 24), ('play', 24), ('friend', 24), ('reach', 23), ('smile', 22), ('care', 21), ('god', 20)]\n[('miss', 42), ('stop', 35), ('demand', 28), ('broke', 23), ('hard', 17), ('shook', 17), ('drop', 14), ('kill', 12), ('bad', 11), ('lost', 11), ('dead', 11), ('forget', 10), ('low', 10), ('violent', 10), ('interrupt', 10)]\n\n\n\nfirst_ch_string = 'In my younger and more vulnerable years'\nsecond_ch_string ='About halfway between West Egg and New York the motor road hastily'\nthird_ch_string ='There was music from my neighbour’s house through the summer nights.'\nfourth_ch_string = 'On Sunday morning while church bells'\nfifth_ch_string = 'When I came home to West Egg that night'\nsixth_ch_string = 'About this time an ambitious young reporter from New York'\nseventh_ch_string ='It was when curiosity about Gatsby was at its highest'\neighth_ch_string = 'I couldn’t sleep all night; a foghorn'\nninth_ch_string = 'After two years I remember the rest of that day'\n\nfirst_ch_index = gatsby_string.find(first_ch_string.lower())\nsecond_ch_index = gatsby_string.find(second_ch_string.lower())\nthird_ch_index = gatsby_string.find(third_ch_string.lower())\nfourth_ch_index = gatsby_string.find(fourth_ch_string.lower())\nfifth_ch_index = gatsby_string.find(fifth_ch_string.lower())\nsixth_ch_index = gatsby_string.find(sixth_ch_string.lower())\nseventh_ch_index = gatsby_string.find(seventh_ch_string.lower())\neighth_ch_index = gatsby_string.find(eighth_ch_string.lower())\nninth_ch_index = gatsby_string.find(ninth_ch_string.lower())\nprint(first_ch_index)\nprint(second_ch_index)\nprint(third_ch_index)\nprint(fourth_ch_index)\nprint(fifth_ch_index)\nprint(sixth_ch_index)\nprint(seventh_ch_index)\nprint(eighth_ch_index)\nprint(ninth_ch_index)\n\n531\n34325\n58543\n91906\n123277\n147460\n170873\n221476\n247570\n\n\n\nscore_arr = []\n\ngatsby_sections = []\ngatsby_sections.append(gatsby_string[first_ch_index:second_ch_index])\ngatsby_sections.append(gatsby_string[second_ch_index:third_ch_index])\ngatsby_sections.append(gatsby_string[third_ch_index:fourth_ch_index])\ngatsby_sections.append(gatsby_string[fourth_ch_index:fifth_ch_index])\ngatsby_sections.append(gatsby_string[fifth_ch_index:sixth_ch_index])\ngatsby_sections.append(gatsby_string[sixth_ch_index:seventh_ch_index])\ngatsby_sections.append(gatsby_string[seventh_ch_index:eighth_ch_index])\ngatsby_sections.append(gatsby_string[eighth_ch_index:ninth_ch_index])\ngatsby_sections.append(gatsby_string[ninth_ch_index:])\nfor section in gatsby_sections:\n  section_list = [w for w in word_tokenize(section.lower()) if w not in stopwords_list]\n  score = 0\n  for word in section_list:\n    val = sia.polarity_scores(word)['compound']\n    score += val\n  score_arr.append(score)\n\nx_coordinate = [ 1+i for i in range(len(score_arr)) ]\nplt.title('Sentiment of the Sections of Gatsby')\nplt.bar(x_coordinate, score_arr)\n\n<BarContainer object of 9 artists>\n\n\n\n\n\n\npositive_words = set(opinion_lexicon.positive())\nnegative_words = set(opinion_lexicon.negative())\n\n\nscore_arr = []\nfor section in gatsby_sections:\n  section_list = [w for w in word_tokenize(section.lower()) if w not in stopwords_list]\n  score = 0\n  for word in section_list:\n    if word in positive_words:\n      score += 1\n    elif word in negative_words:\n      score -= 1\n  score_arr.append(score)\n\nx_coordinate = [ 1+i for i in range(len(score_arr)) ]\nplt.title('Alternate Plot of Section Sentiment') \nplt.bar(x_coordinate, score_arr)\n\n<BarContainer object of 9 artists>\n\n\n\n\n\n\nimport pandas as pd\nx = [w for w in word_tokenize(gatsby_string.lower()) if w not in stopwords_list]\ndf = pd.DataFrame({'words': nltk.FreqDist(x).keys(),\n                   'frequencies': nltk.FreqDist(x).values()})    \n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      words\n      frequencies\n    \n  \n  \n    \n      0\n      great\n      26\n    \n    \n      1\n      gatsby\n      251\n    \n    \n      2\n      f.\n      1\n    \n    \n      3\n      scott\n      1\n    \n    \n      4\n      fitzgerald\n      1\n    \n  \n\n\n\n\n\nnames = ['gatsby', 'nick', 'daisy', 'tom', 'myrtle']\n# df[df[\"words\"] in names]\nnames_df = df.loc[df['words'].isin(names)]\nnames_df.head()\n\n\n\n\n\n  \n    \n      \n      words\n      frequencies\n    \n  \n  \n    \n      1\n      gatsby\n      251\n    \n    \n      590\n      tom\n      188\n    \n    \n      592\n      daisy\n      183\n    \n    \n      974\n      nick\n      24\n    \n    \n      1954\n      myrtle\n      23\n    \n  \n\n\n\n\n\n\nnames_df.plot.bar(x='words', y='frequencies', rot=0, title='Frequencies of Character Names')\n\n<AxesSubplot: title={'center': 'Frequencies of Character Names'}, xlabel='words'>\n\n\n\n\n\n\ntop10_pos_words = []\ntop10_neg_words = []\nfor i in range(10):\n    top10_pos_words.append(top15_pos[i][0])\n    top10_neg_words.append(top15_neg[i][0])\n    \npos_df = df.loc[df['words'].isin(top10_pos_words)]\npos_df.head()\n\n\n\n\n\n  \n    \n      \n      words\n      frequencies\n    \n  \n  \n    \n      0\n      great\n      26\n    \n    \n      50\n      like\n      119\n    \n    \n      126\n      matter\n      19\n    \n    \n      769\n      hand\n      63\n    \n    \n      880\n      laugh\n      9\n    \n  \n\n\n\n\n\nneg_df = df.loc[df['words'].isin(top10_neg_words)]\nneg_df.head()\n\n\n\n\n\n  \n    \n      \n      words\n      frequencies\n    \n  \n  \n    \n      152\n      hard\n      17\n    \n    \n      899\n      miss\n      38\n    \n    \n      1020\n      drop\n      4\n    \n    \n      1149\n      broke\n      23\n    \n    \n      1225\n      bad\n      11\n    \n  \n\n\n\n\n\npos_df.plot.bar(x='words', y='frequencies', rot=0, title='Frequencies of Top 10 Positive Words')\n\n<AxesSubplot: title={'center': 'Frequencies of Top 10 Positive Words'}, xlabel='words'>\n\n\n\n\n\n\nneg_df.plot.bar(x='words', y='frequencies', rot=0, title='Frequencies of Top 10 Negative Words')\n\n<AxesSubplot: title={'center': 'Frequencies of Top 10 Negative Words'}, xlabel='words'>"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myblog",
    "section": "",
    "text": "Gatsby\n\n\n\n\n\nFinal Project\n\n\n\n\n\n\nMar 17, 2023\n\n\nMuthu Palaniappan\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nMar 17, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMar 14, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]